{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["gg2pkigWF-40","GpRkfp7nGDEL","5NEUFY38RwMH","zGVwQhGDUULH","vpfpo4R9mZIk","oSok71_FWlLa","hQaZPZrhkQg_","VsC4OjSbupxc","lopjVrEMxYW4","TAXaNFFVDOAM"],"authorship_tag":"ABX9TyOrcoh8R/2obIyI4U+Vlv2H"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#hide\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SfXuSTVEoTyb","executionInfo":{"status":"ok","timestamp":1664030678032,"user_tz":-330,"elapsed":19663,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"3752d75a-e2c3-4c09-c21b-a60056ad6b95"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["#hide\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","%cd /content/gdrive/My Drive/Colab Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BiB1trTAoUVS","executionInfo":{"status":"ok","timestamp":1664030686134,"user_tz":-330,"elapsed":639,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"ae48a492-ffc6-4fc8-cc9d-c5c27c61320c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["__all__=['camel2snake','Callback','CancelTrainException','CancelEpochException', 'CancelBatchException' ,'Learner' ,'param_getter','TrainEvalCallback', 'AvgStats' ,'AvgStatsCallback', 'Recorder', 'ParamScheduler',\n","         'LR_Find', 'CudaCallback' ,'BatchTransformXCallback', 'view_tfm','ProgressbarCallback' ,'DebugCallback', 'NoneReduce', 'MixUp' ,'Hooks','hook_outputs', 'get_batch' ,'is_lin_layer', 'find_modules','model_summary' ,'cnn_learner' ,\n","         'SaveModelCallback','LoadModelCallback','master_bar','progress_bar','format_time','Beta','unsqueeze','reduce_loss','annealer','cos_1cycle_anneal',\n","         'combine_scheds','create_phases','sched_1cycle','sched_lin','sched_cos','sched_exp', 'sched_no',\n","         'show_results', 'ShowImgsCallback']"],"metadata":{"id":"k3dSMPHY-R_7","executionInfo":{"status":"ok","timestamp":1664030689653,"user_tz":-330,"elapsed":698,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#hide\n","__all__"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wjl8F_K2v0A2","executionInfo":{"status":"ok","timestamp":1664030691940,"user_tz":-330,"elapsed":4,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"48c2c82a-56e0-4953-e507-4764a420bbf8"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['camel2snake',\n"," 'Callback',\n"," 'CancelTrainException',\n"," 'CancelEpochException',\n"," 'CancelBatchException',\n"," 'Learner',\n"," 'param_getter',\n"," 'TrainEvalCallback',\n"," 'AvgStats',\n"," 'AvgStatsCallback',\n"," 'Recorder',\n"," 'ParamScheduler',\n"," 'LR_Find',\n"," 'CudaCallback',\n"," 'BatchTransformXCallback',\n"," 'view_tfm',\n"," 'ProgressbarCallback',\n"," 'DebugCallback',\n"," 'NoneReduce',\n"," 'MixUp',\n"," 'Hooks',\n"," 'hook_outputs',\n"," 'get_batch',\n"," 'is_lin_layer',\n"," 'find_modules',\n"," 'model_summary',\n"," 'cnn_learner',\n"," 'SaveModelCallback',\n"," 'LoadModelCallback',\n"," 'master_bar',\n"," 'progress_bar',\n"," 'format_time',\n"," 'Beta',\n"," 'unsqueeze',\n"," 'reduce_loss',\n"," 'annealer',\n"," 'cos_1cycle_anneal',\n"," 'combine_scheds',\n"," 'create_phases',\n"," 'sched_1cycle',\n"," 'sched_lin',\n"," 'sched_cos',\n"," 'sched_exp',\n"," 'sched_no',\n"," 'show_results',\n"," 'ShowImgsCallback']"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["#hide\n","# !git clone https://github.com/prajwal-suresh13/dl_lib.git"],"metadata":{"id":"b4InV0Nl0MyO","executionInfo":{"status":"ok","timestamp":1664030696821,"user_tz":-330,"elapsed":433,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["from dl_lib.core.utils import *\n","from dl_lib.core.optimizers import *"],"metadata":{"id":"QKidkUGaoZaj","executionInfo":{"status":"ok","timestamp":1664030702771,"user_tz":-330,"elapsed":5456,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from fastprogress.fastprogress import master_bar, progress_bar\n","from fastprogress.fastprogress import format_time"],"metadata":{"id":"ZPq9-SxIjcu4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Learner"],"metadata":{"id":"gg2pkigWF-40"}},{"cell_type":"code","source":["import re\n","_camel_re1 = re.compile('(.)([A-Z][a-z]+)')\n","_camel_re2 = re.compile('([a-z0-9])([A-Z])')\n","\n","def camel2snake(name):\n","    s1 = re.sub(_camel_re1,r'\\1_\\2',name)\n","    return re.sub(_camel_re2, r'\\1_\\2', s1).lower()"],"metadata":{"id":"xQZqzV6PDykY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Callback():\n","    _order=0\n","    def set_learner(self, learner): self.learner = learner\n","    def __getattr__(self, k): return getattr(self.learner, k)\n","\n","    @property\n","    def name(self):\n","        name = re.sub(r'Callback$','', self.__class__.__name__)\n","        return camel2snake(name or 'callback')\n","\n","    def __call__(self, cb_name):\n","        f = getattr(self, cb_name, None)\n","        if f and f(): return True\n","        return False"],"metadata":{"id":"rey2qiQz9SY4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CancelTrainException(Exception): pass\n","class CancelEpochException(Exception): pass\n","class CancelBatchException(Exception): pass\n"],"metadata":{"id":"oHNuzX6z-DY5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def param_getter(m): return m.parameters()"],"metadata":{"id":"VYn1GiPj-XC6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pATi8EWd5nCz"},"outputs":[],"source":["class Learner():\n","    def __init__(self, model, data, loss_func, opt_func=adam_opt, lr=1e-2, splitter=param_getter, cbs=None, cbfuncs = None, plot_hypers=[], metrics={}):\n","        self.model, self.data, self.loss_func, self.opt_func, self.lr, self.splitter= model, data, loss_func, opt_func, lr, splitter\n","        self.in_train, self.logger, self.opt = False, print, None\n","        self.plot_hypers, self.metrics =plot_hypers, metrics\n","\n","        self.cbs = []\n","        self.add_cb(TrainEvalCallback())\n","        self.add_cbs(cbs)\n","        self.add_cbs(cbf() for cbf in listify(cbfuncs))\n","\n","    def add_cbs(self, cbs):\n","        for cb in listify(cbs): self.add_cb(cb)\n","\n","    def add_cb(self, cb):\n","        cb.set_learner(self)\n","        setattr(self, cb.name, cb)\n","        self.cbs.append(cb)\n","\n","\n","    def remove_cbs(self, cbs):\n","        for cb in listify(cbs): self.cbs.remove(cb)\n","\n","    def one_batch(self, i, xb, yb):\n","        try:\n","            self.iter = i\n","            # pdb.set_trace()\n","            self.xb, self.yb = xb, yb;                          self('before_batch')\n","            self.pred = self.model(self.xb) ;                   self('after_pred')\n","            self.loss = self.loss_func(self.pred, self.yb);     self('after_loss')\n","            if not self.in_train: return\n","            self.loss.backward();                                self('after_backward')\n","            self.opt.step();                                     self('after_step')\n","            self.opt.zero_grad(); \n","        except CancelBatchException:                            self('after_cancel_batch')\n","        finally:                                                self('after_batch')  \n","\n","    def all_batches(self):\n","        self.iters = len(self.dl)\n","        try:\n","            for i, (xb,yb) in enumerate(self.dl): self.one_batch(i, xb, yb)\n","        except CancelEpochException:                            self('after_cancel_epoch')   \n","\n","    def do_before_fit(self, epochs):\n","        self.epochs, self.loss = epochs, tensor(0.)\n","        self('before_fit')\n","\n","    def do_before_epoch(self, epoch):\n","        self.epoch, self.dl = epoch, self.data.train_dl\n","        return self('before_epoch')\n","\n","    def fit(self, epochs, cbs=None, reset_opt=False):\n","        self.add_cbs(cbs)\n","\n","        if reset_opt or not self.opt: self.opt = self.opt_func(self.splitter(self.model), lr = self.lr)\n","\n","        try:\n","            self.do_before_fit(epochs)\n","            for epoch in range(epochs):\n","\n","                if not self.do_before_epoch(epoch): self.all_batches()\n","\n","                with torch.no_grad():\n","                    self.dl = self.data.valid_dl\n","                    if not self('before_validate'): self.all_batches()\n","                self('after_epoch') \n","\n","        except CancelTrainException: self('after_cancel_train')\n","        finally:\n","            self('after_fit')\n","            self.remove_cbs(cbs)   \n","\n","    ALL_CBS={'before_batch', 'after_pred', 'after_loss', 'after_backward', 'after_step', 'after_cancel_batch', 'after_batch',\n","                 'after_cancel_epoch', 'before_fit', 'before_epoch','before_validate', 'after_epoch', 'after_cancel_train', 'after_fit' }\n","\n","    def __call__(self, cb_name):\n","        res = False\n","        assert cb_name in self.ALL_CBS \n","        for cb in sorted(self.cbs, key = lambda x: x._order): res = cb(cb_name) and res\n","        return res\n","  "]},{"cell_type":"markdown","source":["# TrainEvalCallback"],"metadata":{"id":"GpRkfp7nGDEL"}},{"cell_type":"code","source":["class TrainEvalCallback(Callback):\n","    def before_fit(self):\n","        self.learner.n_epochs = 0.\n","        self.learner.n_iters = 0\n","\n","    def before_epoch(self):\n","        self.learner.n_epochs = self.epoch\n","        self.model.train()\n","        self.learner.in_train= True\n","\n","    def after_batch(self):\n","        if not self.in_train: return\n","        self.learner.n_epochs +=1./self.iters\n","        self.learner.n_iters +=1\n","\n","    def before_validate(self):\n","        self.model.eval()\n","        self.learner.in_train = False\n","\n","    "],"metadata":{"id":"ipISklfSFLE0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# AvgStatsCallback"],"metadata":{"id":"5NEUFY38RwMH"}},{"cell_type":"code","source":["class AvgStats():\n","    def __init__(self, metrics , in_train): \n","        self.metrics, self.in_train = listify(metrics), in_train\n","\n","    def accumulate(self, learner):\n","        batch_size = learner.yb.shape[0]\n","        self.tot_loss += learner.loss *batch_size\n","        self.count += batch_size\n","        for i,m in enumerate(self.metrics):\n","            self.tot_metrics[i] += m(learner.pred, learner.yb) * batch_size\n","\n","    def reset(self):\n","        self.tot_loss, self.count = 0., 0\n","        self.tot_metrics = [0.] * len(self.metrics)\n","\n","    @property\n","    def all_stats(self):\n","        return [self.tot_loss.item()] + self.tot_metrics\n","\n","    @property\n","    def avg_stats(self):\n","        return [o/self.count for o in self.all_stats]\n","\n","    def __repr__(self):\n","        if not self.count: return \"\"\n","        return f\"{'train'if self.in_train else 'valid'} : {self.avg_stats}\"\n","        \n","\n","\n"],"metadata":{"id":"lsaC39ZdRv66"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class AvgStatsCallback(Callback):\n","    def __init__(self, metrics, valid_stats=True):\n","        self.train_stats =   AvgStats(metrics, True)\n","        self.val=valid_stats\n","        if self.val: self.valid_stats = AvgStats(metrics, False)\n","\n","    def before_fit(self):\n","        met_names = ['loss'] +[m.__name__ for m in self.train_stats.metrics]\n","        names = ['epoch'] + [f'train_{n}' for n in met_names] \n","        if self.val:names+= [f'valid_{n}' for n in met_names] \n","        names+=[f'{name}' for name in self.learner.metrics.keys()]\n","        names += ['time']\n","        self.logger(names)\n","\n","    def before_epoch(self):\n","        self.train_stats.reset()\n","        if self.val:self.valid_stats.reset()\n","        self.start_time = time.time()\n","\n","    def after_loss(self):\n","        stats = self.train_stats if self.in_train else self.valid_stats if self.val  else None\n","        if stats is not None:\n","            with torch.no_grad():stats.accumulate(self.learner)\n","\n","    def after_epoch(self):\n","        stats = [str(self.epoch)]\n","        stats+= [f'{v:.6f}' for v in self.train_stats.avg_stats]\n","        if self.val: stats+= [f'{v:.6f}' for v in self.valid_stats.avg_stats]\n","        for value in self.learner.metrics.values():\n","            try:\n","                l = operator.attrgetter(value)(self.learner) \n","                stats+=[f'{l:.6f}']\n","            except AttributeError as e:\n","                try:\n","                    l = operator.attrgetter(value)(self.learner.loss_func)\n","                    stats+=[f'{l:.6f}']\n","                except AttributeError as e:\n","                    stats+=['Nil'] \n","             \n","\n","        # stats+= [f'{getattr(self.learner, value):.4f}' for value in self.learner.metrics.values()]\n","        stats+= [format_time(time.time() - self.start_time)]\n","        self.logger(stats)\n"],"metadata":{"id":"mg17iVhKSRS8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" # Recorder and ParamScheduler"],"metadata":{"id":"zGVwQhGDUULH"}},{"cell_type":"code","source":["class Recorder(Callback):\n","    def before_fit(self): \n","        self.losses, self.lrs = [],[[] for _ in self.opt.param_groups]\n","        self.hyper_values={}\n","        self.loss_metrics={}\n","        for h in self.learner.plot_hypers:\n","            self.hyper_values[h]=[[] for _ in self.opt.param_groups]\n","\n","        \n","        self.names = self.learner.metrics.keys()\n","        for name in self.learner.metrics.values():\n","            self.loss_metrics[name]=[]\n","\n","\n","\n","    def after_batch(self):\n","        if not self.in_train: return\n","        self.losses.append(self.loss.detach().cpu())\n","        for pg, lr in zip(self.opt.hypers, self.lrs):lr.append(pg['lr'])\n","\n","        for hyper, values in self.hyper_values.items():\n","            for pg,value in zip(self.opt.hypers,values): value.append(pg[hyper])\n","        \n","        for metric,value in self.loss_metrics.items():\n","            try:\n","                l = operator.attrgetter(metric)(self.learner) or operator.attrgetter(metric)(self.learner.loss_func)\n","                value.append(torch.round(l,decimals=3).cpu())\n","            except AttributeError as e:\n","                value.append(0.)\n","\n","    def plot_lr(self, pgid=-1): plt.plot(self.lrs[pgid])\n","\n","    def plot_hypers(self, pgid=-1):\n","        n = len(self.hyper_values.keys())\n","        rows,columns = int(math.ceil(n/2)),2\n","        fig,ax = plt.subplots(rows,columns, figsize=(12,12))\n","        names=list(self.hyper_values.keys())\n","        values=self.hyper_values.values()\n","        \n","        for value,a,name in zip(values,ax.flat,names):\n","            a.plot(value[pgid],label=name)\n","\n","        plt.show()\n","\n","    def plot_loss(self, skip_last=0):\n","        l = len(self.losses)-skip_last\n","        fig,ax = plt.subplots(1,1,figsize=(12,12))\n","        ax.plot(self.losses[:l], label=\"Loss\")\n","        \n","        for name,value in zip(self.names,self.loss_metrics.values()):\n","                ax.plot(value[:l], label=name)\n","\n","        plt.show()\n","\n","    def plot(self, pgid=-1, skip_last=0):\n","        losses = [o.item() for o in self.losses]\n","        lrs = self.lrs[pgid]\n","        n = len(self.losses) - skip_last\n","        plt.xscale('log')\n","        plt.plot(lrs[:n], losses[:n])"],"metadata":{"id":"_-IvVuxaUcrm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ParamScheduler(Callback):\n","    _order = 1\n","    def __init__(self, pname, sched_funcs):\n","        self.pname = pname\n","        self.sched_funcs = listify(sched_funcs)\n","        \n","\n","    def before_batch(self):\n","        if not self.in_train: return\n","        if len(self.sched_funcs) == 1: self.sched_funcs = self.sched_funcs*len(self.opt.param_groups)\n","        assert len(self.sched_funcs) == len(self.opt.param_groups)\n","        for f,hyper in zip(self.sched_funcs,self.opt.hypers):\n","            hyper[self.pname] = f(self.n_epochs/self.epochs)\n","\n"],"metadata":{"id":"tyeKUdA3WNn1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Schedulers"],"metadata":{"id":"8RC0uwmwnPE8"}},{"cell_type":"code","source":["def annealer(f):\n","    def _inner(start, end): return partial(f, start, end)\n","    return _inner\n","\n","@annealer\n","def sched_lin(start, end, pos): return start + pos*(end - start)\n","\n","@annealer\n","def sched_cos(start, end, pos): return start + (1+math.cos(math.pi*(1-pos))) *(end-start)/2\n","\n","@annealer\n","def sched_exp(start, end, pos): return start * (end/start)**pos\n","\n","@annealer\n","def sched_no(start, end, pos): return start\n","\n","def cos_1cycle_anneal(start, high, end):\n","    return [sched_cos(start, high), sched_cos(high, end)]"],"metadata":{"id":"MdPE0KhOnRCd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def combine_scheds(pcts, scheds):\n","    assert sum(pcts)==1.\n","    pcts = tensor([0] + listify(pcts))\n","    assert torch.all(pcts>=0)\n","    pcts = torch.cumsum(pcts,0)\n","    def _inner(pos):\n","        idx = (pos>=pcts).nonzero().max()\n","        if idx==2: idx=1\n","        actual_pos = (pos - pcts[idx])/(pcts[idx+1]-pcts[idx])\n","        return scheds[idx](actual_pos)\n","    return _inner"],"metadata":{"id":"EK7o_HgNowGO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_phases(phases):\n","    phases = listify(phases)\n","    return phases + [1-sum(phases)]"],"metadata":{"id":"xmoU7xhlqynW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def sched_1cycle(lrs, pct_start =0.3, mom_start=0.95, mom_mid=0.85, mom_end=0.95):\n","    phases = create_phases(pct_start)\n","    sched_lr = [combine_scheds(phases, cos_1cycle_anneal(lr/10., lr, lr/1e5)) for lr in lrs]\n","    sched_mom = combine_scheds(phases, cos_1cycle_anneal(mom_start, mom_mid, mom_end))\n","    return [ParamScheduler('lr', sched_lr),\n","            ParamScheduler('mom', sched_mom)]"],"metadata":{"id":"rKanfle6rwPz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#LR Find, CudaCallback, BatchTransformXCallback, ProgressbarCallback, DebugCallback"],"metadata":{"id":"vpfpo4R9mZIk"}},{"cell_type":"code","source":["class LR_Find(Callback):\n","    _order=1\n","    def __init__(self, max_iters = 100, min_lr = 1e-6, max_lr=10):\n","        self.max_iters, self.min_lr, self.max_lr = max_iters, min_lr, max_lr\n","        self.best_loss = 1e9\n","\n","    def before_batch(self):\n","        if not self.in_train: return\n","        pos = self.n_iters/self.max_iters\n","        lr = self.min_lr * (self.max_lr/self.min_lr)**pos\n","        for pg in self.opt.hypers:pg['lr'] = lr\n","\n","    def after_step(self):\n","        if self.n_iters>self.max_iters or self.loss>self.best_loss*10:raise CancelTrainException()\n","        if self.loss < self.best_loss : self.best_loss = self.loss"],"metadata":{"id":"xSnAKRaAma2m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CudaCallback(Callback):\n","    _order = -30\n","    def before_fit(self): self.model.cuda()\n","    def before_batch(self): self.learner.xb, self.learner.yb = self.learner.xb.cuda(), self.learner.yb.cuda()"],"metadata":{"id":"zZhTfN-Uou-k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class BatchTransformXCallback(Callback):\n","    _order=2\n","    def __init__(self, func): self.func = func\n","    def before_batch(self): self.learner.xb = self.func(self.xb)\n","\n","def view_tfm(*size):\n","    def _inner(x): return x.view(*((-1,)+size))\n","    return _inner"],"metadata":{"id":"1RWxA05oo_rr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ProgressbarCallback(Callback):\n","    _order =-100\n","\n","    def before_fit(self):\n","        self.mbar = master_bar(range(self.epochs))\n","        self.mbar.on_iter_begin()\n","        self.learner.logger = partial(self.mbar.write, table=True)\n","\n","    def after_fit(self):self.mbar.on_iter_end()\n","\n","    def set_pb(self):\n","        self.pb = progress_bar(self.dl, parent = self.mbar)\n","        self.mbar.update(self.epoch)\n","\n","    def before_epoch(self): self.set_pb()\n","\n","    def before_validate(self): self.set_pb()\n","    \n","    def after_batch(self): self.pb.update(self.iter)"],"metadata":{"id":"KTnpjzFdkqwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DebugCallback(Callback):\n","    _order = 999\n","    def __init__(self, cb_name, f=None): self.cb_name,self.f = cb_name,f\n","    def __call__(self, cb_name):\n","        if cb_name==self.cb_name:\n","            if self.f: self.f(self.run)\n","            else:      set_trace()"],"metadata":{"id":"evKze961s_lS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MixUP"],"metadata":{"id":"oSok71_FWlLa"}},{"cell_type":"code","source":["from torch.distributions.beta import Beta\n","\n","def unsqueeze(inp, dims):\n","    for dim in listify(dims):inp=torch.unsqueeze(inp,dim)\n","    return inp\n","\n","class NoneReduce():\n","    def __init__(self, loss_func): self.loss_func, self.old_red = loss_func, None\n","\n","    def __enter__(self):\n","        if hasattr(self.loss_func, 'reduction'):\n","            self.old_red = getattr(self.loss_func, 'reduction')\n","            setattr(self.loss_func,'reduction','none')\n","            return self.loss_func\n","        else: return partial(self.loss_func, reduction='none')\n","\n","    def __exit__(self, type, value, traceback):\n","        # print(f'{type}\\n\\n,{value},\\n\\n {traceback}')\n","        if self.old_red is not None: setattr(self.loss_func, 'reduction', self.old_red)\n","\n","def reduce_loss(loss, reduction='mean'):\n","    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss\n","\n","class MixUp(Callback):\n","    _order = 90\n","    def __init__(self, alpha=0.4): self.distrib = Beta(tensor([alpha]), tensor([alpha]))\n","\n","    def before_fit(self):self.old_loss_func, self.learner.loss_func = self.learner.loss_func, self.loss_func\n","\n","    def before_batch(self):\n","        if not self.in_train: return\n","        λ = self.distrib.sample((self.yb.size(0),)).squeeze().to(self.xb.device)\n","        λ = torch.stack([λ, 1-λ],1)\n","        self.λ = unsqueeze(λ.max(1)[0], (1,2,3))\n","\n","        shuffle = torch.randperm(self.yb.size(0))\n","        xb1, self.yb1 = self.xb[shuffle], self.yb[shuffle]\n","        self.learner.xb = lin_comb(self.λ, self.xb, xb1)\n","\n","    def after_fit(self):\n","        self.learner.loss_func = self.old_loss_func\n","\n","    def loss_func(self, pred, yb):\n","        if not self.in_train: return self.old_loss_func(pred, yb)\n","        with NoneReduce(self.old_loss_func) as loss_func:\n","            loss = loss_func(pred, yb)\n","            loss1 = loss_func(pred, self.yb1)\n","        loss = lin_comb(self.λ, loss, loss1)\n","        return reduce_loss(loss, getattr(self.old_loss_func, 'reduction', 'mean'))"],"metadata":{"id":"AlgCtA4VWknx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Hooks"],"metadata":{"id":"hQaZPZrhkQg_"}},{"cell_type":"code","source":["class Hook():\n","    def __init__(self, m, f): self.hook = m.register_forward_hook(partial(f, self))\n","    def remove(self): self.hook.remove()\n","    def __del__(self): self.remove()\n","\n","def append_stats(hook, mod, inp, out):\n","    if not hasattr(hook, 'stats'): hook.stats=([],[])\n","    means, stds = hook.stats\n","    means.append(out.data.mean().cpu())\n","    stds.append(out.data.std().cpu())\n","\n","class Hooks(ListContainer):\n","    def __init__(self, ms, f): super().__init__([Hook(m,f) for m in ms])\n","    def __enter__(self, *args): return self\n","    def __exit__(self, *args): self.remove()\n","    def __del__(self): self.remove()\n","\n","    def __delitem__(self, i):\n","        self[i].remove()\n","        super().__delitem__(i)\n","\n","    def remove(self):\n","        for h in self: h.remove()\n","\n","def hook_outputs(hook, mod, inp, outp):\n","    hook.output = outp"],"metadata":{"id":"v8VZPmCckR5F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Get_batch, Model_summary, is_lin_layer"],"metadata":{"id":"VsC4OjSbupxc"}},{"cell_type":"code","source":["def get_batch(dl, learner):\n","    learner.xb, learner.yb = next(iter(dl))\n","    learner.do_before_fit(0)\n","    learner('before_batch')\n","    learner('after_fit')\n","    return learner.xb, learner.yb\n","\n","def is_lin_layer(l):\n","    lin_layers = (nn.Conv1d, nn.Conv2d, nn.Conv3d, nn.Linear, nn.ReLU)\n","    return isinstance(l, lin_layers)\n","\n","def find_modules(m, cond):\n","    if cond(m): return [m]\n","    return sum([find_modules(o, cond) for o in m.children()],[])\n","\n","\n","def model_summary(learner, find_all=False, print_mod = False):\n","    xb, yb = get_batch(learner.data.valid_dl, learner)\n","    mods = find_modules(learner.model, is_lin_layer) if find_all else learner.model.children()\n","    f = lambda hook, mod, inp, outp: print(f\"========\\n{mod}\\n\" if print_mod else \"\", outp.shape)\n","    with Hooks(mods, f) as hooks: learner.model(xb)"],"metadata":{"id":"pkKH0Mr2utuK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#cnn_learner"],"metadata":{"id":"lopjVrEMxYW4"}},{"cell_type":"code","source":["def cnn_learner(model_arch, data, loss_func, opt_func, c_in=None, c_out=None, lr = 1e-2, cuda=True, norm = None, progress = True, mixup = 0, extra_cbs=None, **kwargs):\n","    cbfs = [partial(AvgStatsCallback, accuracy)] + listify(extra_cbs)\n","    if progress: cbfs.append(ProgressbarCallback)\n","    if cuda    : cbfs.append(CudaCallback)\n","    if norm    : cbfs.append(partial(BatchTransformXCallback, norm))\n","    if mixup   : cbfs.append(partial(MixUp, mixup))\n","    arch_args={}\n","    if not c_in: c_in=data.c_in\n","    if not c_out: c_out=data.c_out\n","    if c_in:arch_args['c_in'] = c_in\n","    if c_out:arch_args['c_out'] = c_out\n","    print(arch_args)\n","    return Learner(model_arch(**arch_args), data, loss_func, opt_func = opt_func, lr=lr, cbfuncs=cbfs, **kwargs)\n","\n"],"metadata":{"id":"4PvopXs3xXs8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Save and Load Model"],"metadata":{"id":"TAXaNFFVDOAM"}},{"cell_type":"code","source":["class SaveModelCallback(Callback):\n","    _order=100\n","    def __init__(self, model_path, interval=2):\n","        self.model_path = model_path\n","        self.interval=interval\n","\n","        if not os.path.exists(self.model_path):\n","            os.mkdir(self.model_path) \n","\n","    def after_epoch(self):\n","        if (self.learner.epoch+1) % self.interval==0:\n","            state = {\n","                'epoch':self.learner.epoch,\n","                'model':self.learner.model.state_dict(),\n","                'optimizer':self.learner.opt.state_dict()\n","            }\n","            \n","            torch.save(state,f'{self.model_path}/{self.epoch}.pth')\n","\n","class LoadModelCallback(Callback):\n","    _order = -50\n","    def __init__(self, model_path, from_start=False, with_opt=True):\n","        self.model_path = model_path\n","        self.with_opt = with_opt\n","        self.from_start = from_start\n","        if not os.path.exists(self.model_path):\n","            print('Invalid model Path')\n","            return\n","        self.state = torch.load(self.model_path)\n","\n","    def before_fit(self):\n","        self.learner.model.load_state_dict(self.state['model'])\n","        if self.with_opt:self.learner.opt.load_state_dict(self.state['optimizer']) \n","    \n","    def before_epoch(self):\n","        if self.from_start:return\n","        self.learner.epoch = self.state['epoch'] +self.learner.epoch +1\n","        if self.learner.epoch == self.learner.epochs:raise CancelTrainException()"],"metadata":{"id":"_zeeLyjZrR06"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"DW2PFoHNDLMU"}},{"cell_type":"markdown","source":["# Display"],"metadata":{"id":"_e5x-Uh36BLv"}},{"cell_type":"code","source":["def show_results(learn, num_of_outputs=5, valid=False,vmin=1,vmax=31):\n","    columns=3\n","    total = num_of_outputs*columns\n","    rows = num_of_outputs\n","    fig,axes = plt.subplots(rows,columns,figsize=(columns*10,rows*10))\n","    i=0\n","    dl = learn.data.valid_dl if valid else learn.data.train_dl\n","    for xb,yb in dl:\n","        for x,y in zip(xb,yb):\n","            show_image(x, axes.flat[i],figsize=(32,32),title='Input')\n","            i+=1\n","            show_image(y, axes.flat[i],figsize=(32,32),title='Target',vmin=vmin, vmax=vmax)\n","            i+=1\n","            \n","            show_image(learn.model.cpu()(x.unsqueeze(0)).argmax(dim=1).squeeze(0), axes.flat[i],figsize=(32,32),title='Prediction',vmin=vmin,vmax=vmax)\n","            i+=1\n","\n","            if i==total:return"],"metadata":{"id":"_BlOKHHC6Yzu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ShowImgsCallback(Callback):\n","    #displays images after each epoch\n","    def __init__(self, show_img_interval=1):\n","        self.show_img_interval=show_img_interval\n","        assert show_img_interval, \"Non_zero allowed\"\n","\n","    def before_fit(self):\n","        self.imgs = []\n","        self.titles = []\n","        assert hasattr(self.learner,'progressbar')\n","\n","    def after_epoch(self):\n","        if (self.learner.epoch+1) % self.show_img_interval == 0:\n","    \n","            self.last_gen = torch.cat((self.learner.xb[1].detach()/2 +0.5,self.learner.yb[1].detach()/2 + 0.5 ,self.learner.pred[1].detach()/2 +0.5),dim=-1)\n","            self.imgs.append(self.last_gen)\n","            self.titles.append(f'Epoch {self.learner.epoch}\\n Input/Target/Prediction')\n","            self.progressbar.mbar.show_imgs(self.imgs, self.titles, imgsize=10)"],"metadata":{"id":"jizLXfgK6DL_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#hide\n","!pip install fire\n","!python dl_lib/notebook2script.py notebooks/core/callbacks.ipynb dl_lib/core"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AjrYAWfVpNh6","executionInfo":{"status":"ok","timestamp":1664030789146,"user_tz":-330,"elapsed":3493,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"396408db-b2fe-4b21-cfe9-282c5905817f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: fire in /usr/local/lib/python3.7/dist-packages (0.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire) (1.1.0)\n","Converted notebooks/core/callbacks.ipynb to dl_lib/core/callbacks.py\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_234oSXh9fJY"},"execution_count":null,"outputs":[]}]}