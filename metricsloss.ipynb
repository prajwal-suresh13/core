{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPclhLfx333a3oG18i3UVxM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#hide\n","from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EYR8KDyX8wAB","executionInfo":{"status":"ok","timestamp":1664034567668,"user_tz":-330,"elapsed":63903,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"689eb951-1547-4362-ab4a-98a5e546584e"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["#hide\n","%load_ext autoreload\n","%autoreload 2\n","\n","%matplotlib inline\n","%cd /content/gdrive/My Drive/Colab Notebooks"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ajLj4DXb8xxG","executionInfo":{"status":"ok","timestamp":1664034575050,"user_tz":-330,"elapsed":674,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"a2bc566e-4a10-4e54-aa53-82ea6a2c2c43"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/My Drive/Colab Notebooks\n"]}]},{"cell_type":"code","source":["__all__ =['LabelSmoothingCrossEntropy', 'accuracy','mse','acc_seg','dice_score', 'CrossEntropyFlat', 'DiceLoss','gram_matrix',\n","          'PerceptualLoss']"],"metadata":{"id":"KyFpufRY7MBH","executionInfo":{"status":"ok","timestamp":1664034609588,"user_tz":-330,"elapsed":3,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["#hide\n","# !git clone https://github.com/prajwal-suresh13/dl_lib.git"],"metadata":{"id":"Ygzw08MI81De"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from dl_lib.core.utils import *\n","from dl_lib.core.callbacks import *"],"metadata":{"id":"cw5Nhyej83g-","executionInfo":{"status":"ok","timestamp":1664034618365,"user_tz":-330,"elapsed":6586,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pqJtAV5v605L"},"outputs":[],"source":["class LabelSmoothingCrossEntropy(nn.Module):\n","    def __init__(self, eta = 0.1, reduction='mean'):\n","        super().__init__()\n","        self.eta, self.reduction = eta, reduction\n","\n","    def forward(self, output, target):\n","        c = output.size()[-1]\n","        log_preds = F.log_softmax(output, dim=-1)\n","        nll = F.nll_loss(log_preds, target, reduction = self.reduction)\n","\n","        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n","\n","        return lin_comb(self.eta, loss/c, nll)"]},{"cell_type":"code","source":["def mse(output, target): return (output.squeeze(-1) - target).pow(2).mean()"],"metadata":{"id":"vQ9HbmvK69Mf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(output, target):\n","    return (torch.argmax(output, dim=1)==target).float().mean()"],"metadata":{"id":"ny2Th0wa7AB-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def acc_seg(input, target, ignore_mask=None):\n","    n=target.shape[0]\n","    target = target.view(n,-1)\n","    input = input.argmax(dim=1).view(n,-1)\n","    if ignore_mask is not None:\n","        mask = target != ignore_mask\n","        return (input[mask]==target[mask]).float().mean()\n","    return (input==target).float().mean()"],"metadata":{"id":"RQTxzE-27YNG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dice_score(pred, target, smooth=1e-6):\n","    num_of_classes = pred.shape[1]\n","    actual_classes = [len(target[i].unique()) for i in range(target.shape[0])]\n","    actual_classes = tensor(actual_classes).cuda()\n","    # print(num_of_classes, actual_classes)\n","\n","    targets = _one_hot(target,num_of_classes)\n","    # print(targets)\n","    preds = F.softmax(pred,dim=1)\n","    # print(preds)\n","    sum_dims = list(range(2,len(pred.shape)))\n","    # print(sum_dims)\n","    intersection = torch.sum(preds*targets,dim=sum_dims)\n","    # print(intersection)\n","    union = torch.sum(preds+targets, dim=sum_dims)\n","    dice_score = ((2. * intersection) / (union )).sum(dim=1)\n","    dice_score/=actual_classes\n","    return dice_score.mean()"],"metadata":{"id":"vJY4JVAO72WY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class CrossEntropyFlat(nn.CrossEntropyLoss):\n","    def forward(self, input, target):\n","        n,c,*_ = input.shape\n","        return super().forward(input.view(n,c,-1), target.view(n,-1))\n","        #https://discuss.pytorch.org/t/multi-class-semantic-segmentation-using-u-net-error-with-binary-cross-entropy-with-logits/85207"],"metadata":{"id":"kl5Sqm-P8Qz2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DiceLoss(nn.Module):\n","    def __init__(self, smooth=0.):\n","        super().__init__()\n","        self.smooth = smooth\n","\n","    def forward(self, pred, target):\n","        dice = dice_score(pred,target, self.smooth)\n","        return 1-dice"],"metadata":{"id":"HP2xzKbk8Yeu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AeW-4PiwC6zF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Perceptual Loss"],"metadata":{"id":"0vVyN8ECDIt4"}},{"cell_type":"code","source":["#hide\n","# from torchvision.models import vgg16_bn\n","# vgg_m = vgg16_bn(True).features.cuda().eval()\n","# for p in vgg_m.parameters():p.requires_grad_(False)\n","\n","#hide\n","# blocks = [i-1 for i,o in enumerate(list(vgg_m.children())) if isinstance(o,nn.MaxPool2d)]\n","# blocks, [vgg_m[i] for i in blocks]"],"metadata":{"id":"YSWE8iJyDKaW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def gram_matrix(x):\n","    n,c,h,w = x.size()\n","    x = x.view(n, c, -1)\n","    return (x @ x.transpose(1,2))/(c*h*w)"],"metadata":{"id":"MXUViSo2D7Qk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PerceptualLoss(nn.Module):\n","    def __init__(self, m_feat, layer_ids, layer_wgts, scale=0.01):\n","        super().__init__()\n","        self.m_feat = m_feat\n","        self.loss_features = [self.m_feat[i] for i in layer_ids]\n","        # self.hooks = Hooks(self.loss_features,hook_outputs)\n","        self.wgts = layer_wgts\n","        self.mean = tensor([0.485, 0.456, 0.406]).cuda() \n","        self.std = tensor([0.229, 0.224, 0.225]).cuda()\n","        self.scale=scale\n","        # self.metric_names = ['pixel',] + [f'feat_{i}' for i in range(len(layer_ids))\n","        #       ] + [f'gram_{i}' for i in range(len(layer_ids))]\n","\n","    def make_features(self, x, clone=False):\n","        with Hooks(self.loss_features, hook_outputs)as hooks:\n","            self.m_feat(x)\n","            return [(h.output.clone() if clone else h.output) for h in hooks]\n","            # return [print(h.output) for h in hooks]\n","            \n","    \n","    def forward(self, input, target):\n","        input,target= (input/tensor([2.]).cuda())+tensor([0.5]).cuda() ,(target/tensor([2.]).cuda())+tensor([0.5]).cuda()\n","        input,target = (input-self.mean[...,None,None])/self.std[...,None,None] , (target-self.mean[...,None,None])/self.std[...,None,None]\n","        out_feat = self.make_features(target, clone=True)\n","        in_feat = self.make_features(input)\n","        self.feat_losses = [F.l1_loss(input,target)]\n","        self.feat_losses += [F.l1_loss(f_in, f_out)*w\n","                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n","        self.feat_losses += [F.l1_loss(gram_matrix(f_in), gram_matrix(f_out))*w**2 * 5e3\n","                             for f_in, f_out, w in zip(in_feat, out_feat, self.wgts)]\n","        # self.metrics = dict(zip(self.metric_names, self.feat_losses))\n","        self.feat_losses=sum(self.feat_losses) *self.scale\n","        # print(self.feat_losses)\n","        return self.feat_losses\n","    \n","   "],"metadata":{"id":"P-5lB8jfPP0U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#hide\n","!pip install fire\n","!python dl_lib/notebook2script.py notebooks/core/metricsloss.ipynb dl_lib/core"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqir8OAx9BOO","executionInfo":{"status":"ok","timestamp":1664034640488,"user_tz":-330,"elapsed":8256,"user":{"displayName":"Prajwal S","userId":"14513618843540613764"}},"outputId":"31c2e9c2-c7dd-4a73-9e4b-527aeea5aaee"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fire\n","  Downloading fire-0.4.0.tar.gz (87 kB)\n","\u001b[K     |████████████████████████████████| 87 kB 4.8 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire) (1.1.0)\n","Building wheels for collected packages: fire\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=1d13dd303303539127b6cab91c839e771b19c87764c403616bf20609cc2ca45b\n","  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n","Successfully built fire\n","Installing collected packages: fire\n","Successfully installed fire-0.4.0\n","Converted notebooks/core/metricsloss.ipynb to dl_lib/core/metricsloss.py\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"nBKe7Osi9ix2"},"execution_count":null,"outputs":[]}]}